# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json

# Learn more about building a configuration: https://promptfoo.dev/docs/configuration/guide

description: "My eval"

prompts:
  - "Write a customer service response to:\n\n{{inquiry}}\n\nUse these documents:\n\n{{context}}"
  
providers:
  - id: google:gemini-2.5-flash
    config:
      apiKey: AIzaSyDpzT3XyY_GrsZyW-gcX-X3PNd75ZZ3_XY
  

tests:
  - vars:
      inquiry: ". Soy un camper, programador junior perteneciente a campuslands , iniciando mi proceso de formación, perteneciente a la ruta NodeJs, me gustaría saber ¿Cuánto tiempo puede tardar un proyecto?, quiero que me entregues un texto informativo referente a cada proyecto según su skill , su plazo y dificultad."
      context: file://context.js

  - vars:
      inquiry: ". Soy un camper, programador junior perteneciente a campuslands , iniciando mi proceso de formación, perteneciente a la ruta NodeJs, me gustaría saber ¿Cuánto tiempo puede tardar un proyecto?, quiero que me entregues un texto informativo referente a cada proyecto según su skill , su plazo y dificultad."
      context: file://context.js     

  - vars:
      inquiry: ". Soy un programador junior perteneciente a campuslands , perteneciente a la sedecajasan , con un número de identificación xxxx , ¿Con quién puedo gestionar ingresohacia zona franca?, quiero que me entregues el contacto para poder entrar a zonafranca"
      # See how to use dynamic context to e.g. use a vector store https://promptfoo.dev/docs/guides/evaluate-rag/#using-dynamic-context
      context: file://context.js
    assert:
      # For more information on assertions, see https://promptfoo.dev/docs/configuration/expected-outputs

      # Make sure output contains the phrase "return label"
      - type: icontains
        value: "return label"

      # Prefer shorter outputs
      - type: javascript
        value: 1 / (output.length + 1)

  - vars:
      inquiry: "I need help with my account"
      context: |
        You can also hardcode context directly in the configuration.
        Username: Foobar
        Account ID: 123456
    assert:
      # For more information on model-graded evals, see https://promptfoo.dev/docs/configuration/expected-outputs/model-graded
      - type: llm-rubric
        value: ensure that the output is friendly and empathetic
